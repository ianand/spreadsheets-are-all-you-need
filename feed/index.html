<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/">
<channel>
<title>Spreadsheets are all you need.ai</title>
<atom:link href="https://spreadsheets-are-all-you-need.ai/feed/" rel="self" type="application/rss+xml"></atom:link>
<link/>https://spreadsheets-are-all-you-need.ai
	<description>Learn AI topics using familiar tools</description>
<lastbuilddate>Wed, 04 Jun 2025 15:39:36 +0000</lastbuilddate>
<language>en-US</language>
<sy:updateperiod>
	hourly	</sy:updateperiod>
<sy:updatefrequency>
	1	</sy:updatefrequency>
<item>
<title>SessionSorter for AI Engineer World’s Fair 2025</title>
<link/>https://spreadsheets-are-all-you-need.ai/sessionsorter-for-ai-engineer-worlds-fair-2025/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Wed, 04 Jun 2025 15:37:29 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=1641</guid>
<description><![CDATA[OpenAI API Key Your Prompt help me decide between these sessions Ask ChatGPT Hide Sessions &#215;]]></description>
<content:encoded><![CDATA[
  <style>
    /* Namespace: csp- for "Conference Session Picker" */
    body.csp-body {
      font-family: system-ui, -apple-system, sans-serif;
      margin: 0;
      padding: 2rem;
      background: #f9fafb;
      color: #111827;
    }

    h1.csp-heading {
      font-size: 1.75rem;
      margin-bottom: 1rem;
    }

    #csp-apiKeyContainer {
      margin-bottom: 1rem;
      max-width: 640px;
    }

    #csp-stickyControls {
      position: sticky;
      top: 75px;
      left: 0;
      right: 0;
      background: #f9fafb;
      padding: 1rem 2rem;
      z-index: 10;
      display: flex;
      flex-direction: column;
      gap: 0.75rem;
      border-bottom: 1px solid #e5e7eb;
    }

    label.csp-label {
      font-weight: 600;
      display: block;
    }

    textarea.csp-textarea, input[type="text"].csp-input {
      padding: 0.5rem;
      border: 1px solid #d1d5db;
      border-radius: 0.375rem;
      width: 100%;
      font-size: 0.95rem;
    }

    button.csp-button {
      position: relative;
      background: #3b82f6;
      color: white;
      padding: 0.6rem 1.25rem;
      border: none;
      border-radius: 0.375rem;
      cursor: pointer;
      font-weight: 600;
      transition: background 0.2s;
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
    }

    button.csp-button:disabled {
      background: #9ca3af;
      cursor: not-allowed;
    }

    button.csp-button:hover:not(:disabled) {
      background: #2563eb;
    }

    .csp-spinner {
      width: 1rem;
      height: 1rem;
      border: 2px solid #e5e7eb;
      border-top-color: #3b82f6;
      border-radius: 50%;
      animation: csp-spin 1s linear infinite;
    }

    @keyframes csp-spin {
      to { transform: rotate(360deg); }
    }

    #csp-toggleSessions {
      margin-bottom: 1rem;
      background: transparent;
      color: #3b82f6;
      padding: 0;
      border: none;
      font-weight: 600;
      cursor: pointer;
    }

    table.csp-table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 2rem;
      max-width: none;
    }

    th.csp-th, td.csp-td {
      padding: 0.75rem 0.5rem;
      border-bottom: 1px solid #e5e7eb;
      vertical-align: top;
      text-align: left;
    }

    tr.csp-timeslot > th.csp-th {
      background: #f3f4f6;
      font-size: 1rem;
      font-weight: 700;
      width: 160px;
    }

    .csp-session {
      display: flex;
      align-items: flex-start;
      gap: 0.5rem;
      padding: 0.25rem 0;
    }

    .csp-session input[type="checkbox"] {
      margin-top: 4px;
      accent-color: #3b82f6;
      cursor: pointer;
    }

    .csp-session-details {
      flex: 1;
      cursor: pointer;
    }

    .csp-session-title {
      font-weight: 600;
    }

    .csp-detailsBtn {
      background: #10b981;
      padding: 0.25rem 0.5rem;
      font-size: 0.85rem;
      border-radius: 0.375rem;
      border: none;
      color: white;
      cursor: pointer;
      transition: background 0.2s;
    }
    .csp-detailsBtn:hover {
      background: #059669;
    }

    #csp-response {
      background: #f3f4f6;
      border-radius: 0.375rem;
      padding: 1rem;
      margin-top: 1rem;
      max-width: 640px;
    }

    /* Modal styles */
    .csp-modal {
      display: none;
      position: fixed;
      z-index: 10000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      overflow: auto;
      background-color: rgba(0,0,0,0.4);
    }
    .csp-modal-content {
      background-color: #fff;
      margin: 10% auto;
      padding: 1rem;
      border: 1px solid #888;
      width: 90%;
      max-width: 600px;
      border-radius: 0.375rem;
    }
    .csp-modal-close {
      color: #aaa;
      float: right;
      font-size: 1.5rem;
      font-weight: bold;
      cursor: pointer;
    }
    .csp-modal-close:hover,
    .csp-modal-close:focus {
      color: #000;
      text-decoration: none;
    }
  </style>
  <!-- Marked.js for Markdown rendering -->
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <!-- API Key separate, not sticky -->
  <div id="csp-apiKeyContainer">
    <label class="csp-label">
      OpenAI API Key
      <input id="csp-apiKey" class="csp-input" type="password" placeholder="sk-..." />
    </label>
  </div>

  <!-- Only prompt and button are sticky -->
  <section id="csp-stickyControls">
    <label class="csp-label">
      Your Prompt
      <textarea id="csp-prompt" class="csp-textarea" rows="3">help me decide between these sessions</textarea>
    </label>

    <button id="csp-askBtn" class="csp-button" disabled>
      Ask ChatGPT
      <span id="csp-spinner" class="csp-spinner" hidden></span>
    </button>
  </section>

  <button id="csp-toggleSessions" class="csp-button">Hide Sessions</button>
  <div id="csp-sessionsContainer">
    <table id="csp-sessionTable" class="csp-table"></table>
  </div>

  <div id="csp-response" class="csp-response" hidden></div>

  <!-- Modal for session details -->
  <div id="csp-modal" class="csp-modal">
    <div class="csp-modal-content">
      <span id="csp-modalClose" class="csp-modal-close">&times;</span>
      <h2 id="csp-modalTitle"></h2>
      <p id="csp-modalSpeakers"></p>
      <p id="csp-modalDescription"></p>
    </div>
  </div>

  <script>
    // --- CONFIG ---
    const csp_SESSIONS_URL = "https://sessionize.com/api/v2/w3hd2z8a/view/All";
    const csp_DETAILS_URL = "https://www.ai.engineer/sessions-speakers-details.json";

    // --- State ---
    let csp_sessions = [];
    let csp_speakers = new Map();

    // --- Helpers ---
    function csp_formatTime(iso) {
      const d = new Date(iso);
      return d.toLocaleString([], {
        month: "short",
        day: "numeric",
        hour: "2-digit",
        minute: "2-digit",
      });
    }

    function csp_groupBy(array, keyFn) {
      return array.reduce((acc, item) => {
        const key = keyFn(item);
        (acc[key] = acc[key] || []).push(item);
        return acc;
      }, {});
    }

    function csp_render() {
      const table = document.getElementById("csp-sessionTable");
      table.innerHTML = "";

      // Sort sessions by start time
      csp_sessions.sort((a, b) => new Date(a.startsAt) - new Date(b.startsAt));

      const grouped = csp_groupBy(csp_sessions, (s) => s.startsAt);

      for (const [start, list] of Object.entries(grouped)) {
        const tr = document.createElement("tr");
        tr.classList.add("csp-timeslot");
        const th = document.createElement("th");
        th.classList.add("csp-th");
        th.textContent = `${csp_formatTime(start)}`;
        tr.appendChild(th);

        const td = document.createElement("td");
        td.classList.add("csp-td");
        list.forEach((s) => {
          const div = document.createElement("div");
          div.className = "csp-session";

          const cb = document.createElement("input");
          cb.type = "checkbox";
          cb.dataset.id = s.id;

          const detailsDiv = document.createElement("div");
          detailsDiv.className = "csp-session-details";
          detailsDiv.innerHTML = `
            <div class="csp-session-title">${s.title}</div>
            <div class="csp-session-speakers">${s.speakerNames.join(", ")}</div>
          `;
          // Toggle checkbox when clicking on details text
          detailsDiv.addEventListener("click", () => {
            cb.checked = !cb.checked;
          });

          const detailsBtn = document.createElement("button");
          detailsBtn.className = "csp-detailsBtn";
          detailsBtn.textContent = "Details";
          detailsBtn.dataset.id = s.id;
          detailsBtn.addEventListener("click", () => csp_showModal(s.id));

          div.appendChild(cb);
          div.appendChild(detailsDiv);
          div.appendChild(detailsBtn);
          td.appendChild(div);
        });
        tr.appendChild(td);
        table.appendChild(tr);
      }
    }

    async function csp_loadData() {
      const askBtn = document.getElementById("csp-askBtn");
      const spinner = document.getElementById("csp-spinner");
      // Show spinner and keep button disabled
      askBtn.disabled = true;
      spinner.hidden = false;

      try {
        const [data1, data2] = await Promise.all([
          fetch(csp_SESSIONS_URL).then((r) => r.json()),
          fetch(csp_DETAILS_URL).then((r) => r.json()).catch(() => ({})),
        ]);

        // Build speaker map from first file
        if (Array.isArray(data1.speakers)) {
          data1.speakers.forEach((sp) => {
            csp_speakers.set(sp.id, sp.fullName || `${sp.firstName} ${sp.lastName}`);
          });
        }

        // Merge sessions (prefer detailed description from second URL)
        const sessionsById = new Map();
        if (Array.isArray(data1.sessions)) {
          data1.sessions.forEach((s) => sessionsById.set(String(s.id), s));
        }
        if (Array.isArray(data2)) {
          data2.forEach((s) => {
            const existing = sessionsById.get(String(s["Session ID"]));
            if (existing) {
              existing.description = s.Description || existing.description;
            }
          });
        }

        csp_sessions = Array.from(sessionsById.values()).map((s) => ({
          id: s.id,
          title: s.title || s.Title,
          description: s.description || s.Description || "",
          startsAt: s.startsAt || s["Scheduled At"],
          speakerIds: s.speakers || [],
          speakerNames: (s.speakers || []).map((id) => csp_speakers.get(id) || id),
        }));

        csp_render();
      } catch (err) {
        alert(`Error loading sessions: ${err.message}`);
      } finally {
        // Hide spinner, enable ask button once data is loaded or on error
        spinner.hidden = true;
        document.getElementById("csp-askBtn").disabled = false;
      }
    }

    function csp_showModal(sessionId) {
      const session = csp_sessions.find((s) => s.id == sessionId);
      if (!session) return;
      document.getElementById("csp-modalTitle").textContent = session.title;
      document.getElementById("csp-modalSpeakers").textContent = 'Speakers: ' + session.speakerNames.join(', ');
      document.getElementById("csp-modalDescription").textContent = session.description;
      document.getElementById("csp-modal").style.display = "block";
    }

    function csp_hideModal() {
      document.getElementById("csp-modal").style.display = "none";
    }

    async function csp_callChatGPT(prompt, talks, apiKey) {
      const message = [prompt.trim(), "\n\n", ...talks.map((t) => `${t.title}: ${t.description}`)].join("\n\n");

      const res = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          messages: [{ role: "user", content: message }],
        }),
      });

      if (!res.ok) throw new Error(`OpenAI error: ${res.status}`);
      const data = await res.json();
      return data.choices?.[0]?.message?.content?.trim() || "(No response)";
    }

    document.addEventListener("DOMContentLoaded", () => {
      const apiInput = document.getElementById("csp-apiKey");
      // Load from localStorage if available
      const savedKey = localStorage.getItem("openai_key");
      if (savedKey) apiInput.value = savedKey;

      // Save to localStorage on change
      apiInput.addEventListener("input", () => {
        localStorage.setItem("openai_key", apiInput.value.trim());
      });

      const askBtn = document.getElementById("csp-askBtn");
      const spinner = document.getElementById("csp-spinner");
      const sessionsContainer = document.getElementById("csp-sessionsContainer");
      const toggleBtn = document.getElementById("csp-toggleSessions");
      const modal = document.getElementById("csp-modal");
      const modalClose = document.getElementById("csp-modalClose");

      // Toggle sessions visibility
      toggleBtn.addEventListener("click", () => {
        const hidden = sessionsContainer.hidden;
        sessionsContainer.hidden = !hidden;
        toggleBtn.textContent = hidden ? "Hide Sessions" : "Show Sessions";
      });

      // Close modal
      modalClose.addEventListener("click", csp_hideModal);
      window.addEventListener("click", (event) => {
        if (event.target == modal) {
          csp_hideModal();
        }
      });

      askBtn.addEventListener("click", async () => {
        const apiKey = apiInput.value.trim();
        if (!apiKey) {
          alert("Please enter your OpenAI API key.");
          return;
        }

        // Save key just before sending
        localStorage.setItem("openai_key", apiKey);

        const prompt = document.getElementById("csp-prompt").value;
        const checked = Array.from(document.querySelectorAll(".csp-session input[type=checkbox]:checked"));
        if (checked.length === 0) {
          alert("Please pick at least one session.");
          return;
        }
        const selected = csp_sessions.filter((s) => checked.some((cb) => cb.dataset.id == s.id));

        // Hide sessions, update toggle text
        sessionsContainer.hidden = true;
        toggleBtn.textContent = "Show Sessions";

        // Disable button & show spinner during ChatGPT call
        askBtn.disabled = true;
        spinner.hidden = false;

        try {
          const reply = await csp_callChatGPT(prompt, selected, apiKey);
          const respDiv = document.getElementById("csp-response");
          respDiv.hidden = false;
          // Render markdown to HTML
          respDiv.innerHTML = marked.parse(reply);
          window.scrollTo({ top: respDiv.offsetTop, behavior: "smooth" });
        } catch (err) {
          alert(err.message);
        } finally {
          askBtn.disabled = false;
          spinner.hidden = true;
        }
      });

      // Initial load
      csp_loadData();
    });
  </script>
]]></content:encoded>
</item>
<item>
<title>If you’re not using AI 20 times a day, you might be doing your job wrong.</title>
<link/>https://spreadsheets-are-all-you-need.ai/if-youre-not-using-ai-20-times-a-day-you-might-be-doing-your-job-wrong/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Fri, 09 May 2025 19:36:42 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=1562</guid>
<description><![CDATA[A year ago, I half jokingly proposed that “If you're not using AI 20 times a day, you're probably doing your job wrong.” In multiple instances over the past month, ...]]></description>
<content:encoded><![CDATA[
<figure class="wp-block-embed is-provider-youtube wp-block-embed-youtube"><div class="wp-block-embed__wrapper">
<iframe title="If you&#039;re not using AI 20 times a day, you might be doing your job wrong." width="800" height="450" src="https://www.youtube.com/embed/5cL6j650m-Y?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>A year ago, I half jokingly proposed that <em><a href="https://x.com/ianand/status/1783741240657477650">“If you're not using AI 20 times a day, you're probably doing your job wrong.”</a></em></p>



<p>In multiple instances over the past month, we've seen that prediction become official corporate policy.</p>



<p>Companies like <a href="https://www.investing.com/news/stock-market-news/ibm-ceo-sees-ai-reshaping-workforce-and-enterprise-strategy-4025923">IBM</a>, <a href="https://www.businessinsider.com/internal-artificial-intelligence-solutions-banking-companies-employee-training-2025-5">Morgan Stanley, Bank of America</a>, <a href="https://www.marketplace.org/episode/2025/05/06/fiverr-ceo-micha-kaufman-explains-why-everyone-needs-to-upskill-with-ai">Fiverr</a>, and most publicly, Shopify are making AI usage <em>mandatory</em>. In <a href="https://x.com/tobi/status/1909251946235437514">a leaked internal memo</a>, Shopify stated that “<strong>Reflexive AI usage is now a baseline expectation</strong>” and will be <strong>part of performance reviews</strong>.</p>



<p>And yet, many professionals still aren’t using AI regularly. Why? Because despite all the hype using AI well isn’t always obvious.</p>



<p>At a recent event on AI in HR, someone admitted to me they felt behind and didn’t even know where to begin. So I gave them two starting points:</p>



<h3 class="wp-block-heading">1. Set an “AI Step Count”</h3>



<p>Think of it like your Fitbit goal, but for your brain. Try to use tools like ChatGPT, Claude, Copilot, or Gemini <strong>20 times a day</strong>. Since the <a href="https://zapier.com/blog/work-resolutions-report/">average knowledge worker works a 10 hour day</a>, that’s roughly every 30 minutes in a typical workday. If you go an hour without using AI, you’ve probably missed a chance to flex your AI muscle.</p>



<h3 class="wp-block-heading">2. Replace Your Search Engine with a Chatbot</h3>



<p>This is the easiest upgrade. Change your browser’s default search box to a chatbot. The search box is ideal because it latches onto a habit you already have. And it assuages data concerns: if you're willing to type data into a search engine, it's probably safe to type into an AI search tool as well.</p>



<p>Tools like ChatGPT have browser extensions, but you can also configure Claude or Gemini manually in your browser search settings. In the video, I show this for Chrome.</p>



<h3 class="wp-block-heading">How are you upskilling on AI?</h3>



<p>I’m currently researching how teams are upskilling for AI: What skills are missing? Which tools matter most? If you're navigating this shift individually or inside your organization, I’d love to hear what you’re learning. Please reach out.</p>
]]></content:encoded>
</item>
<item>
<title>Why AI’s ROI is Hiding In Plain Sight</title>
<link/>https://spreadsheets-are-all-you-need.ai/why-ais-roi-is-hiding-in-plain-sight/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Tue, 06 May 2025 23:03:34 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=1554</guid>
<description><![CDATA[You've probably encountered the headlines of companies struggling to see financial returns from their AI investments or executives cancelling AI rollouts due to disappointing ROI, and skepticism around AI's value ...]]></description>
<content:encoded><![CDATA[
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe title="Why AI&#039;s ROI is Hiding In Plain Sight" width="800" height="450" src="https://www.youtube.com/embed/u5_X4DVHRck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a class="wp-block-button__link wp-element-button" href="https://docs.google.com/spreadsheets/d/1x8nIUzuPUI2kNeTyyu0seKCSbx19ojI7G-eefAtaWHs/edit?usp=sharing">Spreadsheet from the video</a></div>
</div>



<p>You've probably encountered the headlines of <a href="https://www.wsj.com/articles/companies-are-struggling-to-drive-a-return-on-ai-it-doesnt-have-to-be-that-way-f3d697aa">companies struggling to see financial returns</a> from their AI investments or  <a href="https://www.ciocoverage.com/pharma-company-drops-microsoft-copilot-ai-due-to-high-costs-and-limited-value-sparking-industry-concerns/">executives cancelling AI rollouts due to disappointing ROI</a>, and skepticism around AI's value in the enterprise. Yet, paradoxically, if you've personally used AI tools, you've likely felt their value. Why is there this disconnect?</p>



<h3 class="wp-block-heading">The Disconnect Explained</h3>



<p>Imagine a hypothetical company with three employees:</p>



<ul class="wp-block-list">
<li><strong>Alice (Product)</strong>: Highly skilled in product management, but less so in engineering and marketing.</li>



<li><strong>Bob (Engineering)</strong>: Expert engineer but weaker in product and marketing.</li>



<li><strong>Eve (Marketing)</strong>: Expert in marketing, with minimal skills in product and engineering.</li>
</ul>



<p>Collectively, the company's competencies are strong across product, engineering, and marketing because each employee excels in their specialty. But what happens when we introduce AI?</p>



<p><a href="https://hai.stanford.edu/news/will-generative-ai-make-you-more-productive-work-yes-only-if-youre-not-already-great-your-job">Research</a> shows that <a href="https://mitsloan.mit.edu/ideas-made-to-matter/workers-less-experience-gain-most-generative-ai#:~:text=%E2%80%9CGenerative%20AI%20seems%20to%20be,they%20can%20get%20better%20faster.%E2%80%9D">AI disproportionately boosts the productivity of non-experts</a>, transforming them into "quasi-experts". In our hypothetical company, that means Alice, Bob, and Eve each become significantly better in areas outside their core expertise. For example, Alice can now handle engineering tasks reasonably well, Bob becomes decent at marketing, and Eve can engage effectively with product tasks. </p>



<p>Individually, this represents massive gains in versatility but most organizations are structured by speciality. Alice's newfound engineering skill or Bob's marketing insight is lost if their roles and workflows remain rigidly segmented. The gains in individual productivity may not translate to organizational ROI without changes to the company's structure.</p>



<h3 class="wp-block-heading">Lessons from the Past</h3>



<p>This scenario mirrors past historical technology transitions. For example, in transition from steam power to electricity, it took factories nearly 50 years to recognize the productivity gains. It took decades before factory owners realized they needed to reorganize completely, breaking away from centralized power sources of steam-power and redesign their workflows to fully leverage electricity's potential.</p>



<p>Similarly, to capture the full value of AI, organizations must reconsider and possibly reinvent their structures and workflows.</p>



<h3 class="wp-block-heading">The Frontier Firm, The Frontier Job</h3>



<p><a href="https://www.microsoft.com/en-us/worklab/work-trend-index">Microsoft’s 2025 Work Trend Index</a> provides a glimpse into this future, introducing the concept of "Frontier Firms," organizations where humans initially leverage AI assistants but eventually lead autonomous teams of AI agents. </p>



<p>The startup Oleve is an illustrative example. <a href="https://www.youtube.com/watch?v=aDiEQngFsFU">As discussed on the Latent Space podcast</a>, this small company is generating outsized recurring revenue by empowering "product engineers" who blend multiple skillsets and enabling by AI agents to tackle tasks from product discovery to marketing.</p>



<p>AI has the potential to redefine <a href="https://platforms.substack.com/p/the-many-fallacies-of-ai-wont-take">your organization, your market and even the problem you're solving for your customers</a>.</p>



<p>For organizations seeking meaningful ROI from AI, the question isn't merely "How can AI speed up our existing processes?" Instead, leaders should ask, "How must our processes evolve because of AI?"</p>



<h3 class="wp-block-heading">Recommended Reading</h3>



<p><a href="https://x.com/karpathy/status/1909308143156240538">Power to the people: How LLMs flip the script on technology diffusion</a></p>



<p><a href="https://platforms.substack.com/p/the-many-fallacies-of-ai-wont-take">The many fallacies of 'AI won't take your job, but someone using AI will'</a></p>
]]></content:encoded>
</item>
<item>
<title>LlamaCon 2025 Bingo</title>
<link/>https://spreadsheets-are-all-you-need.ai/llamacon-2025-bingo/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Tue, 29 Apr 2025 07:18:46 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=1539</guid>
<description><![CDATA[Today is LlamaCon, the first official virtual conference for Meta’s open-source Llama models. I don’t have any inside information about what will be announced, so I decided to ask the ...]]></description>
<content:encoded><![CDATA[
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe title="LlamaCon 2025 Bingo" width="800" height="450" src="https://www.youtube.com/embed/rbvfD1SvX1c?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>Today is LlamaCon, the first official virtual conference for Meta’s open-source Llama models.</p>



<p>I don’t have any inside information about what will be announced, so I decided to ask the model itself. Using the Together AI playground, I asked Llama 4 Maverick 17B to predict some possible announcements and format them as bingo card labels, based on a few recent news articles.</p>



<p>Since this is <em>Spreadsheets Are All You Need</em>, I set it up in a spreadsheet. You can make a copy, ask your favorite model what might happen, and update the bingo card yourself.</p>



<p>So grab the popcorn, play along, and enjoy LlamaCon.</p>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a class="wp-block-button__link wp-element-button" href="https://docs.google.com/spreadsheets/d/1vqzHY-SUZ0Y7cr7MaW7p8yxDGrc8oPdBAj4cCaqypHI/edit?usp=sharing">LlamaCon 2025 Bingo Card Google Sheet</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading">Update: Llama-as-Judge evaluates LlamaCon 2025</h2>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Llama-as-a-Judge judges LlamaCon 2025 Bingo" width="800" height="450" src="https://www.youtube.com/embed/H4J3GqefauY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>As a follow-up, I fed Llama4 transcripts from the event and asked it to judge how well its Bingo Card did. Unfortunately, despite Llama accurately predicting more than half the talking points, it failed to get a Bingo by a single square in multiple cases. </p>



<p>You can watch the video and read the transcript of the model's judgements below.</p>



<p><em>Disclosure notice: The content below was generated with AI.</em></p>



</pre><h3>Llama 4 Variants</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the first Bingo Card label "Llama 4 Variants" qualifies for being marked off.

The transcripts mention several variants of Llama 4, including:

Llama 4 Scout: a smaller model that runs on a single H100 and is best-in-class on several benchmarks for its size.
Llama 4 Maverick: a 17 billion active parameter model used in production for several Meta products, including Meta AI.
Llama 4 Behemoth: a massive model, one of the largest out there, used as a teacher model to improve the performance of Maverick.
These announcements indicate that there are multiple variants of Llama 4, which directly corresponds to the Bingo Card label "Llama 4 Variants".

Therefore, the answer is: Yes, the Bingo Card label "Llama 4 Variants" can be marked off.

</pre><h3> Multimodal Capabilities</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Multimodal Capabilities" qualifies for being marked off.

The transcripts mention several instances of multimodal capabilities:

Chris Cox mentions that Llama 4 is "massively multimodal" and supports multiple modalities, including text, images, and potentially other modalities.
Angela Fan and Manohar Paluri discuss how Llama 4 was designed to be natively multimodal, with a training recipe that interweaves different modalities, such as text and images.
The Llama 4 models are described as being able to take image input and send multiple images per prompt.
Chris Cox highlights the use of a perception encoder, a visual encoder that works well across many visual domains, which is used in tools like SAM 2 (object detection system for image and video).
These announcements and discussions indicate that Llama 4 has multimodal capabilities, which directly corresponds to the Bingo Card label "Multimodal Capabilities".

Therefore, the answer is: Yes, the Bingo Card label "Multimodal Capabilities" can be marked off.

</pre><h3> Agentic AI</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Agentic AI" qualifies for being marked off.

The transcripts mention several instances related to Agentic AI:

Mark Zuckerberg and Ali Ghodsi discuss the concept of "agents" and how they are being used to automate tasks, such as customer support and coding.
Ali Ghodsi mentions that one of the big trends is the development of "agents" that can navigate the web and use computers.
Mark Zuckerberg talks about building "coding agents" and "AI research agents" that can advance Llama research.
Satya Nadella discusses the concept of "agents" and how they are being used in Microsoft's products, such as GitHub Copilot, to automate tasks and improve productivity.
These discussions and mentions indicate that Agentic AI is a topic of interest and discussion at the LlamaCon event, and that companies like Meta and Microsoft are working on developing and integrating agentic AI capabilities into their products.

Therefore, the answer is: Yes, the Bingo Card label "Agentic AI" can be marked off.

</pre><h3> Fine-tuning APIs</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Fine-tuning APIs" qualifies for being marked off.

The transcripts mention several instances related to Fine-tuning APIs:

Manohar Paluri and Angela Fan discuss the Llama API, which allows developers to fine-tune Llama models for their specific use cases.
Angela Fan explains that the Llama API provides a fine-tuning tab where developers can upload data, configure hyperparameters, and fine-tune their models.
The Llama API is described as allowing developers to take their custom models with them wherever they want to host them, without being locked into Meta's servers.
The news article "Everything we announced at our first-ever LlamaCon" also mentions that the Llama API provides tools for fine-tuning and evaluation, allowing developers to customize and run their models more efficiently.

These announcements and discussions indicate that the Llama API provides fine-tuning capabilities, which directly corresponds to the Bingo Card label "Fine-tuning APIs".

Therefore, the answer is: Yes, the Bingo Card label "Fine-tuning APIs" can be marked off.

</pre><h3> Nvidia Partnership</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Nvidia Partnership" qualifies for being marked off.

The news article "Everything we announced at our first-ever LlamaCon" mentions that Meta has collaborated with partners to build Llama Stack distributions, including a recently announced integration of Llama Stack with NVIDIA NeMo microservices.

This announcement indicates a partnership between Meta and Nvidia, which directly corresponds to the Bingo Card label "Nvidia Partnership".

Therefore, the answer is: Yes, the Bingo Card label "Nvidia Partnership" can be marked off.

</pre><h3> GPU Roadmap</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "GPU Roadmap" qualifies for being marked off.

Upon reviewing the transcripts and news articles, I did not find any direct mention of a "GPU Roadmap". While there are discussions about hardware and infrastructure related to AI, such as the need for more compute power and the development of specialized hardware like the H100, there is no explicit mention of a GPU roadmap.

The closest related discussion is Mark Zuckerberg's mention of the need for physical infrastructure, including compute and energy, to support the growth of AI. He also mentions that NVIDIA needs time to stabilize their new generation of systems.

However, this is not a direct announcement or discussion of a GPU roadmap.

Therefore, the answer is: No, the Bingo Card label "GPU Roadmap" cannot be marked off based on the provided information.

</pre><h3> WhatsApp Integration</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "WhatsApp Integration" qualifies for being marked off.

The transcripts mention that Meta AI is "most used in WhatsApp" (Mark Zuckerberg's interview). This indicates that there is an integration of Meta AI with WhatsApp.

Therefore, the answer is: Yes, the Bingo Card label "WhatsApp Integration" can be marked off.

</pre><h3> Paid API Tiers</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Paid API Tiers" qualifies for being marked off.

The transcripts mention a discussion about monetizing AI, where Mark Zuckerberg talks about the possibility of having a premium service that supports people using arbitrary amounts of compute to do more amazing things. He states that "for that, I'm sure we'll end up having a premium service" (Mark Zuckerberg's interview).

This indicates that Meta is considering or planning to have paid tiers for their AI services, which could be related to the API.

Therefore, the answer is: Yes, the Bingo Card label "Paid API Tiers" can be marked off.

</pre><h3> EU Privacy Concerns</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "EU Privacy Concerns" qualifies for being marked off.

Upon reviewing the transcripts and news articles, I did not find any direct mention of "EU Privacy Concerns". While there are discussions about data privacy and security, such as the Llama API being designed with a focus on data privacy and security, and not using user prompts or model responses to train AI models, there is no explicit mention of EU-specific privacy concerns.

Therefore, the answer is: No, the Bingo Card label "EU Privacy Concerns" cannot be marked off based on the provided information.

</pre><h3> Llama 5 Teaser</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Llama 5 Teaser" qualifies for being marked off.

Upon reviewing the transcripts and news articles, I found a mention of "Llama 5 B model" by Angela Fan, where she talks about the synthetic data tool kits that help generate good post-training data for use cases, and mentions that there will be more information on this topic.

However, this is not a direct teaser for Llama 5, but rather a mention of a related topic.

Mark Zuckerberg also mentions "Little Llama" as an internal code name for a future Llama model, but it's not clear if this refers to Llama 5.

There is no explicit teaser or announcement for Llama 5.

Therefore, the answer is: No, the Bingo Card label "Llama 5 Teaser" cannot be marked off based on the provided information.

</pre><h3> Open Source Development</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Open Source Development" qualifies for being marked off.

The transcripts and news articles are filled with discussions and announcements about open source development, including:

Chris Cox's opening remarks highlighting the importance of open source AI and the growth of the Llama ecosystem.
Mark Zuckerberg and Ali Ghodsi's discussion on the benefits of open source AI, including the ability to customize and fine-tune models.
Satya Nadella's discussion on Microsoft's commitment to supporting open source models and providing a platform for developers to build on top of them.
The announcement of the Llama API, which is designed to provide a flexible and open way for developers to build with Llama models.
The news article "Everything we announced at our first-ever LlamaCon" highlights Meta's commitment to open source AI and the Llama ecosystem.
These discussions and announcements demonstrate a strong focus on open source development and the Llama ecosystem.

Therefore, the answer is: Yes, the Bingo Card label "Open Source Development" can be marked off.

</pre><h3> Meta AI</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Meta AI" qualifies for being marked off.

The transcripts and news articles mention Meta AI multiple times, including:

Chris Cox's discussion on the Meta AI app, which was launched during the event, and its features, such as full-duplex voice and personalization.
Mark Zuckerberg's discussion on Meta AI, including its usage and growth, with almost a billion monthly active users.
The Meta AI app is described as a standalone app that provides a new experience for users, with features like voice interface and personalization.
These discussions and announcements demonstrate a significant focus on Meta AI, its features, and its growth.

Therefore, the answer is: Yes, the Bingo Card label "Meta AI" can be marked off.

</pre><h3> Developer Tools</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Developer Tools" qualifies for being marked off.

The transcripts and news articles mention several developer tools and features, including:

The Llama API, which provides a lightweight SDK in Python and Typescript, and is compatible with the OpenAI SDK.
Interactive playgrounds to explore different Llama models.
Fine-tuning and evaluation tools for customizing Llama models.
Synthetic data tool kits to help generate good post-training data for use cases.
Satya Nadella's discussion on Microsoft's developer tools, including GitHub Copilot, which is being used to improve developer productivity.
These discussions and announcements demonstrate a significant focus on providing developer tools and features to support the growth of the Llama ecosystem.

Therefore, the answer is: Yes, the Bingo Card label "Developer Tools" can be marked off.

</pre><h3> Meta AI Web Interface</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Meta AI Web Interface" qualifies for being marked off.

The transcripts mention the launch of a new Meta AI app, which is a standalone app that provides a new experience for users. Chris Cox discusses the app's features, including a voice interface and personalization.

However, there is no explicit mention of a "Meta AI Web Interface". The discussion is focused on the Meta AI app, which is a mobile or standalone application, rather than a web interface.

Therefore, the answer is: No, the Bingo Card label "Meta AI Web Interface" cannot be marked off based on the provided information.

</pre><h3> Enterprise Licensing</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Enterprise Licensing" qualifies for being marked off.

The transcripts mention a discussion between Mark Zuckerberg and the interviewer about the Llama license, including the requirement for companies to contact Meta if they want to use Llama models and reach 700 million users.

Mark Zuckerberg states that the goal of the license is to have a conversation with large cloud companies, like Microsoft and Amazon, before they use Llama models, and to find a productive way to work together.

This discussion implies that there are licensing terms and conditions for enterprise use of Llama models, which is related to the concept of "Enterprise Licensing".

Therefore, the answer is: Yes, the Bingo Card label "Enterprise Licensing" can be marked off.

</pre><h3> Ray-Ban Smart Glasses</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Ray-Ban Smart Glasses" qualifies for being marked off.

The transcripts mention Ray-Ban Meta glasses, which are described as being "incredibly popular" and having AI capabilities. Chris Cox discusses how the Meta AI app focuses on taking the experience of using the glasses and making it coherent, whether you're using the glasses or your phone.

Mark Zuckerberg also mentions the Ray-Ban Meta product as an example of a successful augmented reality product that "gets out of the way" and is a good-looking pair of glasses.

These discussions indicate that Ray-Ban Smart Glasses (or Ray-Ban Meta glasses) are being referenced and discussed during the event.

Therefore, the answer is: Yes, the Bingo Card label "Ray-Ban Smart Glasses" can be marked off.

</pre><h3> Horizon Avatars</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Horizon Avatars" qualifies for being marked off.

The transcripts mention "Codec Avatars" by Mark Zuckerberg, which is a technology related to creating realistic digital avatars. He discusses how this technology can be used to create a more immersive experience, such as having an "always-on video chat with the AI" with realistic gestures.

However, there is no explicit mention of "Horizon Avatars". While Codec Avatars is a related concept, it is not the same as Horizon Avatars.

Therefore, the answer is: No, the Bingo Card label "Horizon Avatars" cannot be marked off based on the provided information.

</pre><h3> Cloud Integrations</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Cloud Integrations" qualifies for being marked off.

The transcripts and news articles mention several cloud integrations, including:

A discussion between Mark Zuckerberg and Satya Nadella about the importance of cloud infrastructure for AI development and deployment.
The news article "Everything we announced at our first-ever LlamaCon" mentions that Meta has collaborated with partners to build Llama Stack distributions, including integrations with NVIDIA NeMo microservices, IBM, Red Hat, Dell Technologies, and others.
These discussions and announcements indicate that there are cloud integrations being developed and announced, which directly corresponds to the Bingo Card label "Cloud Integrations".

Therefore, the answer is: Yes, the Bingo Card label "Cloud Integrations" can be marked off.

</pre><h3> AI Infrastructure Investments</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "AI Infrastructure Investments" qualifies for being marked off.

The transcripts mention several discussions related to AI infrastructure investments, including:

Mark Zuckerberg's discussion on the need for significant investments in physical infrastructure, including compute and energy, to support the growth of AI.
Mark Zuckerberg mentions that building a gigawatt cluster of compute requires significant infrastructure investments, including building data centers and obtaining energy.
Satya Nadella discusses the importance of building out infrastructure, including compute, storage, and networking, to support AI workloads.
These discussions indicate that there are significant investments being made in AI infrastructure, which directly corresponds to the Bingo Card label "AI Infrastructure Investments".

Therefore, the answer is: Yes, the Bingo Card label "AI Infrastructure Investments" can be marked off.

</pre><h3> Databricks Partnership</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Databricks Partnership" qualifies for being marked off.

The transcripts include a conversation between Mark Zuckerberg and Ali Ghodsi, the CEO of Databricks, where they discuss the use of Llama models on the Databricks platform and the benefits of open-source AI.

This conversation indicates a partnership or collaboration between Meta and Databricks, which directly corresponds to the Bingo Card label "Databricks Partnership".

Therefore, the answer is: Yes, the Bingo Card label "Databricks Partnership" can be marked off.

</pre><h3> Together AI Integration</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Together AI Integration" qualifies for being marked off.

Upon reviewing the transcripts and news articles, I did not find any mention of "Together AI Integration". The discussions and announcements are focused on other topics, such as Llama models, Meta AI, and partnerships with companies like Nvidia and Databricks.

Therefore, the answer is: No, the Bingo Card label "Together AI Integration" cannot be marked off based on the provided information.

</pre><h3> Groq Partnership</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Groq Partnership" qualifies for being marked off.

The news article "Everything we announced at our first-ever LlamaCon" mentions a collaboration between Meta and Cerebras and Groq to provide faster inference speeds using the Llama API. It states that early experimental access to Llama 4 models powered by Cerebras and Groq are available by request.

This announcement indicates a partnership between Meta and Groq, which directly corresponds to the Bingo Card label "Groq Partnership".

Therefore, the answer is: Yes, the Bingo Card label "Groq Partnership" can be marked off.

</pre><h3> Reasoning Model</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Reasoning Model" qualifies for being marked off.

The transcripts mention several discussions related to reasoning models, including:

Mark Zuckerberg's discussion on the importance of reasoning models, which consume more test-time or inference-time compute to provide more intelligence.
Mark Zuckerberg mentions that Meta is building a Llama 4 reasoning model, which will be released at some point.
Ali Ghodsi discusses the trend of using reasoning models and the importance of distillation and fine-tuning for specific tasks.
These discussions indicate that reasoning models are a topic of interest and development, and that Meta is working on building a Llama 4 reasoning model.

Therefore, the answer is: Yes, the Bingo Card label "Reasoning Model" can be marked off.

</pre><h3> Meta Connect</h3><pre>

Based on the provided transcripts and news articles from the LlamaCon event, I can help you determine if the Bingo Card label "Meta Connect" qualifies for being marked off.

Upon reviewing the transcripts and news articles, I did not find any mention of "Meta Connect". The discussions and announcements are focused on LlamaCon, Llama models, and related topics.

Meta Connect is likely a different event or conference, and there is no indication that it was discussed or announced during LlamaCon.

Therefore, the answer is: No, the Bingo Card label "Meta Connect" cannot be marked off based on the provided information.
]]></content:encoded>
</item>
<item>
<title>ArrrZero: Why DeepSeek R1 is less important than R1-Zero</title>
<link/>https://spreadsheets-are-all-you-need.ai/arrrzero-why-deepseek-r1-is-less-important-than-r1-zero/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Fri, 14 Mar 2025 21:57:23 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=285</guid>
<description><![CDATA[The headlines about DeepSeek R1's cost are missing an even bigger story, the R1-Zero model. This model, and research behind it, are reshaping how we thought AI assistants should be ...]]></description>
<content:encoded><![CDATA[
<p>The headlines about DeepSeek R1's cost are missing an even bigger story, the R1-Zero model. This model, and research behind it, are reshaping how we thought AI assistants should be trained.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="ArrrZero: Why DeepSeek R1 is less important than R1-Zero" width="800" height="450" src="https://www.youtube.com/embed/DE6WpzsSvgU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>





<p>To understand why the R1-Zero model matters, we have to look at how AI chatbots like ChatGPT are typically created. When an AI model is trained on text from the internet, the resulting model is actually pretty dumb. Chatting with it is useless because it only knows how to literally imitate text on the internet. For example, in the <a href="https://www.youtube.com/watch?v=DE6WpzsSvgU">video for this blog post</a>, when the model (called a "base model") is given a prompt like "First Name:", it replies "Name:, Address:". Essentially, the model is trying to guess what kind of web page might contain the prompt and then replies with the imagined content from the rest of that hypothetical web page. In this case, it sees "First Name:" and guesses it's part of a form, so it replies with the rest of the form (i.e. Address). This is effective enough for crafting <a href="https://openai.com/index/better-language-models/">fake news stories about Unicorns</a> but it can't carry a conversation nor answer user questions directly.</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h49m48s411-1024x576.png" alt="" class="wp-image-1534" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h49m48s411-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h49m48s411-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h49m48s411-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h49m48s411.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>To turn this "base model" (also known as a "pretrained model") into a chatbot like ChatGPT has typically involved a complex and labor-intensive process. The process requires the three major steps shown in the diagram below (adapted from the <a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">State of GPT</a>) that are labeled "Supervised Finetuning", "Reward Modeling", and "Reinforcement Learning".</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h48m07s751-1024x576.png" alt="" class="wp-image-1533" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h48m07s751-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h48m07s751-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h48m07s751-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h48m07s751.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>The "Supervised Finetuning" step requires humans to write thousands of example conversations teaching the model how a helpful AI assistant should behave. Even once the model has learned from those examples, humans are needed to grade the quality of the responses the model produces which further fine tunes the quality of the model in a process called "Reinforcement Learning from Human Feedback (RLHF)".</p>



<p>DeepSeek R1-Zero changes the game by eliminating most of this human work. Instead of requiring armies of people to train and fine-tune the AI, it uses math and coding problems to teach the AI how to think and reason. Because these problems have clear right and wrong answers, computers can automatically check if the AI is correct without any human oversight needed.</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h55m01s210-1024x576.png" alt="" class="wp-image-1535" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h55m01s210-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h55m01s210-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h55m01s210-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h55m01s210.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>"It's an aha moment, not just for the model, but for the researchers," notes the DeepSeek team, describing the moment their AI learned to catch its own mistakes and consider different approaches to problems.</p>



<p>This breakthrough could accelerate AI development by removing what experts call the "human bottleneck" (the need for extensive human input in training AI systems). It's already being recognized as a major advancement, with some experts considering it even more significant than other recent AI developments that have grabbed headlines.</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h56m15s271-1024x576.png" alt="" class="wp-image-1536" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h56m15s271-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h56m15s271-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h56m15s271-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/03/vlcsnap-2025-03-14-14h56m15s271.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>What makes this particularly exciting is that several teams have already successfully reproduced similar results using smaller-scale versions of this approach, suggesting this could become a new standard way of creating AI assistants that can think and reason effectively.</p>



<p>As AI continues to evolve, DeepSeek R1-Zero's innovative training method might just be the key to creating smarter AI assistants more quickly and efficiently than ever before.</p>
]]></content:encoded>
</item>
<item>
<title>FLOPS Demystified: AI and the math behind DeepSeek training costs</title>
<link/>https://spreadsheets-are-all-you-need.ai/flops-demystified-ai-and-the-math-behind-deepseek-training-costs/
		
		<dc:creator><![CDATA[ishan@spreadsheets-are-all-you-need.ai]]></dc:creator>
<pubdate>Sat, 22 Feb 2025 18:24:09 +0000</pubdate>
<category><![CDATA[Uncategorized]]></category>
<guid ispermalink="false">https://spreadsheets-are-all-you-need.ai/?p=1508</guid>
<description><![CDATA[This might be my most important AI article yet but it's also my biggest FLOP. FLOPs are one of the most fundamental metrics in AI. To understand how AI works ...]]></description>
<content:encoded><![CDATA[
<style>
.entry-content {
font-size: 1.35em;
}
</style>



<p>This might be my most important AI article yet but it's also my biggest FLOP.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="FLOPS Demystified: AI and the math behind DeepSeek training costs" width="800" height="450" src="https://www.youtube.com/embed/T3JiBtHHTMU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>FLOPs are one of the most fundamental metrics in AI. To understand how AI works and what it costs to train amazing models like ChatGPT or DeepSeek, you need to understand FLOPs.</p>



<p>In the accompanying video and this article we will:</p>



<ul class="wp-block-list">
<li>Explore the difference between FLOP, FLOPS, &amp; FLOPs</li>



<li>Reveal why AI is fundamentally different from traditional software&nbsp;</li>



<li>Crack open GPT-2 (using spreadsheets-are-all-you-need) to count every FLOP</li>



<li>Apply these insights to analyze DeepSeek's viral "$5.3M training cost" claim and uncover what this number really means (and what it doesn't)</li>
</ul>



<h2 class="wp-block-heading"><strong>What Are FLOPs?</strong></h2>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h21m07s002-1024x576.png" alt="" class="wp-image-1509" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h21m07s002-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h21m07s002-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h21m07s002-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h21m07s002.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>FLOP stands for FLoating point OPeration. Any basic mathematical operation (like addition or multiplication) performed on decimal numbers is considered a FLOP. For example, if you add 5.2 and 4.4 to get 9.6 you just did a single FLOP.</p>



<p>Confusingly, FLOPs (with a lowercase 's') and FLOPS (with a capital 'S') are different:&nbsp;</p>



<ul class="wp-block-list">
<li>FLOPs (with a lowercase 's'): how many floating point operations occur</li>



<li>FLOPS (with a capital 'S'): how many operations happen per second.</li>
</ul>



<p>As an analogy you can think of FLOPs as “miles” (a quantity of something) and FLOPS as "miles per hour" (how fast that number changes over time).</p>



<h2 class="wp-block-heading"><strong>Why FLOPs Matter in AI</strong></h2>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m47s438-1024x576.png" alt="" class="wp-image-1510" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m47s438-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m47s438-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m47s438-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m47s438.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>Traditional software applications like Microsoft Word or PowerPoint primarily use logic and control flow statements - if/then conditions, loops, and function calls. AI models, particularly large language models, work fundamentally differently. They convert words into numbers, perform massive amounts of mathematical operations on these numbers, and then convert the resulting numbers back into words.</p>



<p>Let's look at a simplified example. You’ve probably heard that AI models are trained to fill in the blank and complete passages like this one: "Mike is quick. He moves ___".&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m33s130-1024x576.png" alt="" class="wp-image-1511" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m33s130-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m33s130-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m33s130-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h18m33s130.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>To solve this, the AI model will,</p>



<ol class="wp-block-list">
<li>Convert each word into floating point numbers (aka decimal numbers)</li>



<li>Perform complex mathematical calculations on those numbers</li>



<li>Produce a final decimal number</li>



<li>Maps that final decimal number back to the known words in its vocabulary, with closer matches getting higher probabilities</li>
</ol>



<p>For our example passage "Mike is quick. He moves ___", words like "quickly" and "fast" would be chosen in step 4 because they map to numbers that are close to the model's calculated result in step 3.</p>



<h2 class="wp-block-heading"><strong>Measuring FLOPs in Practice</strong></h2>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m03s059-1024x576.png" alt="" class="wp-image-1512" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m03s059-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m03s059-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m03s059-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m03s059.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>Using the <a href="https://spreadsheets-are-all-you-need.ai/gpt2/">web version of Spreadsheets Are All You Need</a>, we can actually count these operations in a real language model without leaving our browser. Watch the accompanying video and follow along the steps yourself to see how easy it is to actually count FLOPs!</p>



<p>When processing just six tokens (words or parts of words), GPT-2 Small performs approximately one billion floating point operations.&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m35s154-1024x576.png" alt="" class="wp-image-1513" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m35s154-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m35s154-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m35s154-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m35s154.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>This matches closely with theoretical estimates derived from the model's architecture. A common useful estimate is that the number of FLOPs needed to process one token is approximately two times the number of parameters in the model. This makes sense when you consider that each neuron in a neural network primarily performs two operations (multiplication and addition) for each parameter.</p>



<h2 class="wp-block-heading"><strong>Understanding AI Training Costs</strong></h2>



<p>This brings us to the recent discussion around DeepSeek's training costs. DeepSeek reported spending $5.3 million to train their latest model. As we show in the video, this estimate does line up with theoretical estimates and the reported data from their technical report:</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m53s008-1024x576.png" alt="" class="wp-image-1514" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m53s008-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m53s008-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m53s008-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h19m53s008.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>Unfortunately, this led to articles like the one below, comparing this figure to OpenAI's reported $5 billion in development costs.&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m19s557-1024x576.png" alt="" class="wp-image-1515" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m19s557-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m19s557-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m19s557-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m19s557.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p><strong>This comparison is deeply misleading.</strong></p>



<p>The $5.3 million represents just the GPU compute costs for the final training run. It doesn't include:</p>



<ul class="wp-block-list">
<li>Costs of research and experimentation leading up to the final architecture</li>



<li>Failed training attempts</li>



<li>Data collection and processing</li>



<li>Personnel costs</li>



<li>Infrastructure beyond raw compute</li>
</ul>



<p>Yes DeepSeek probably spent $5.4 million on their <strong>final</strong> training run <strong>but</strong> that was not the total amount they spent to build the model.</p>



<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m47s867-1024x576.png" alt="" class="wp-image-1516" srcset="https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m47s867-1024x576.png 1024w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m47s867-300x169.png 300w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m47s867-768x432.png 768w, https://spreadsheets-are-all-you-need.ai/wp-content/uploads/2025/02/vlcsnap-2025-02-22-10h20m47s867.png 1280w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>Think of it like measuring the cost of building a house by only counting the lumber used in the final construction. Yes, lumber is a significant expense, but it's far from the total cost of creating a house.</p>



<h2 class="wp-block-heading"><strong>The Reality of Model Development</strong></h2>



<p>As I argue in the video, the development of frontier AI models is more akin to Thomas Edison's journey to create the light bulb. Edison didn't just build one light bulb. He made nearly 3,000 attempts before finding a design that worked. Each attempt represented real costs in materials, time, and labor.</p>



<p>Similarly, creating a successful AI model requires numerous experiments, failed attempts, and iterations. The final training run is just the tip of a very expensive iceberg.</p>



<p>The next time you see headlines about FLOPs or AI training costs, hopefully you’ll now be better prepared to not only understand them but also put them in the proper context.&nbsp;</p>



<p>Best of luck on your AI journey.</p>
]]></content:encoded>
</item>
</channel>
</rss>
